import logging
from abc import ABC, abstractmethod
from functools import reduce
from typing import Callable, List
from pathlib import Path
import pprint

import z3
import dreal
import numpy as np
import sympy as sp
import torch
import torch.nn as nn

from maraboupy import Marabou
from maraboupy import MarabouCore

from envs import Box, Env


logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)


class Verifier(ABC):
  @abstractmethod
  def __init__(
      self,
      models: List[nn.Sequential],
      env: Env,
      F: Callable
  ):
    ...

  @abstractmethod
  def chk(self) -> List[List]:
    ...


# Representation of ReLU in SymPy
ReLU = sp.Function('ReLU')


def X(dim):
  """Representation of a vector named x in SymPy."""
  return sp.Matrix(
    [sp.Symbol(f'x_{i}') for i in range(dim)] )


def Y(dim):
  return sp.Matrix(
    [sp.Symbol(f'y_{i}') for i in range(dim)])


def Net(net: nn.Sequential, x: sp.Matrix):
  """Representation of a ReLU-activated NN in SymPy.
  
  Args:
    net: an instance of nn.Sequential. We assume all layers are 
    instances of either nn.Linear (fully connected feed-forward) or 
    nn.ReLU (activation functions).
    x: input matrix.
  """
  for layer in net:
    if isinstance(layer, nn.Linear):
      W = layer.weight.data.numpy()
      # If the layer has no bias, we simply set bias to 0.
      # Expand_dims changes a 1D vector into a 2D column vector.
      b = (
        layer.bias.data.numpy()
        if layer.bias is not None
        else np.zeros(len(W)) )
      b = np.expand_dims(b, 1)
      x = W @ x + b
    if isinstance(layer, nn.ReLU):
      x = x.applyfunc(ReLU)
  return x


def BoundIn(box: Box, x):
  B = []
  dim = len(box.low)
  low = box.low.numpy()
  high = box.high.numpy()
  B += [x[i] >= low[i] for i in range(dim)]
  B += [x[i] <= high[i] for i in range(dim)]
  return reduce(lambda a, b: a & b, B)


def BoundOut(box: Box, x):
  B = []
  dim = len(box.low)
  low = box.low.numpy()
  high = box.high.numpy()
  B += [x[i] <= low[i] for i in range(dim)]
  B += [x[i] >= high[i] for i in range(dim)]
  return reduce(lambda a, b: a | b, B)


def Norm_L1(x):
  acc = sp.Abs(x[0])
  for i in range(1, len(x)):
    acc += sp.Abs(x[i])
  return acc


def solve_z3(C, x):
  """Satisfying model for C, generated by Z3.
  If a model exists for C, this function returns a list 
  [y_1, ..., y_k], where y_i = model[x_i].
  
  Assumption. All variables in x are Real.
  
  Args:
    C: A list of Z3 constraints.
    x: A list of Z3 variables.
  """
  s = z3.Solver()
  s.add(C)
  chk = s.check()
  if chk == z3.sat:
    m = s.model()
    n = len(x)
    return [float(m[x[i]].as_fraction()) for i in range(n)]
  elif chk == z3.unsat:
    return []
  else:
    raise RuntimeError('unknown result for SMT query')


def solve_dreal(F, x, delta=1e-3):
  """Satisfying model for C, generated by DReal."""
  result = dreal.CheckSatisfiability(F, delta)
  if not result:
    return []
  return [result[x[i]].mid() for i in range(len(x))]


def sympy_to_z3(expr, var):
  """Translate SymPy expression to Z3.

  Args:
    expr: SymPy expression.
    var: a dictionary mapping SymPy Symbols to their Z3 equivalents. 
  """
  match expr:
    case sp.Symbol():
      return var[expr]
    case sp.Number():
      return expr
    case sp.Add():
      acc = sympy_to_z3(expr.args[0], var)
      for arg in expr.args[1:]:
        acc += sympy_to_z3(arg, var)
      return acc
    case sp.Mul():
      acc = sympy_to_z3(expr.args[0], var)
      for arg in expr.args[1:]:
        acc *= sympy_to_z3(arg, var)
      return acc
    case sp.And():
      args = [sympy_to_z3(arg, var) for arg in expr.args]
      return z3.And(args)
    case sp.Or():
      args = [sympy_to_z3(arg, var) for arg in expr.args]
      return z3.Or(args)
    case sp.Abs():
      arg = sympy_to_z3(expr.args[0], var)
      return z3.If(arg < 0, -arg, arg)
    case sp.Function():
      if expr.name != 'ReLU':
        raise NotImplementedError(type(expr), expr.name)
      arg = sympy_to_z3(expr.args[0], var)
      return z3.If(arg < 0, 0, arg)
    case sp.GreaterThan():
      l, r = [sympy_to_z3(arg, var) for arg in expr.args]
      return l >= r
    case sp.LessThan():
      l, r = [sympy_to_z3(arg, var) for arg in expr.args]
      return l <= r
    case sp.StrictGreaterThan():
      l, r = [sympy_to_z3(arg, var) for arg in expr.args]
      return l > r
    case sp.StrictLessThan():
      l, r = [sympy_to_z3(arg, var) for arg in expr.args]
      return l < r
    case _:
      raise NotImplementedError(type(expr))


def sympy_to_dreal(expr, var):
  """Translate SymPy expression to DReal.

  Args:
    expr: SymPy expression.
    var: a dictionary mapping SymPy Symbols to their DReal equivalents.
  """
  if isinstance(expr, sp.Symbol):
    return var[expr]
  if isinstance(expr, sp.Number):
    return expr
  if isinstance(expr, sp.Add):
    acc = sympy_to_dreal(expr.args[0], var)
    for arg in expr.args[1:]:
      acc += sympy_to_dreal(arg, var)
    return acc
  if isinstance(expr, sp.Mul):
    acc = sympy_to_dreal(expr.args[0], var)
    for arg in expr.args[1:]:
      acc *= sympy_to_dreal(arg, var)
    return acc
  if isinstance(expr, sp.And):
    args = [sympy_to_dreal(arg, var) for arg in expr.args]
    return dreal.And(*args)
  if isinstance(expr, sp.Or):
    args = [sympy_to_dreal(arg, var) for arg in expr.args]
    return dreal.Or(*args)
  if isinstance(expr, sp.GreaterThan):
    l, r = [sympy_to_dreal(arg, var) for arg in expr.args]
    return l >= r
  if isinstance(expr, sp.LessThan):
    l, r = [sympy_to_dreal(arg, var) for arg in expr.args]
    return l <= r
  if isinstance(expr, sp.StrictGreaterThan):
    l, r = [sympy_to_dreal(arg, var) for arg in expr.args]
    return l > r
  if isinstance(expr, sp.StrictLessThan):
    l, r = [sympy_to_dreal(arg, var) for arg in expr.args]
    return l < r
  # Functions
  if isinstance(expr, sp.Abs):
    arg = sympy_to_dreal(expr.args[0], var)
    return dreal.if_then_else(arg > 0, arg, 0)
  if isinstance(expr, sp.sin):
      arg = sympy_to_dreal(expr.args[0], var)
      return dreal.sin(arg)
  if isinstance(expr, sp.cos):
    arg = sympy_to_dreal(expr.args[0], var)
    return dreal.cos(arg)
  if isinstance(expr, sp.exp):
    arg = sympy_to_dreal(expr.arg[0], var)
    return dreal.exp(arg)
  if isinstance(expr, sp.Function) and expr.name == 'ReLU':
    arg = sympy_to_dreal(expr.args[0], var)
    return dreal.if_then_else(arg < 0, 0, arg)
  raise NotImplementedError(type(expr))


# Verifiers are named after their corresponding learners. Concretely, 
# Verifier_W (where W is a string) corresponds to Learner_W.

class Verifier_Reach_C(Verifier):
  def __init__(self, models, env, F):
    self.cert = models[0]
    self.env = env
    self.F = F

  def chk(self):
    return [self.chk_dec()]

  def chk_dec(self):
    x_sp = X(self.env.dim)
    x_z3 = z3.RealVector('x', self.env.dim)
    var = {x_sp[i]: x_z3[i] for i in range(self.env.dim)}
    v, vf = z3.Real('v'), z3.Real('vf')

    # The lists bound and problem contain SymPy expressions for
    # variable bounds and problem constrains.
    bounds, problem = [], []
    bounds.append(BoundIn(self.env.bnd, x_sp))
    bounds.append(BoundOut(self.env.tgt, x_sp))
    bounds = [sympy_to_z3(b, var) for b in bounds]
    problem.append(
      v  == sympy_to_z3( Net(self.cert, x_sp)[0], var) )
    problem.append(
      vf == sympy_to_z3( Net(self.cert, self.F(x_sp))[0], var) )
    problem.append(v <= vf)
    logger.debug('bounds=' + pprint.pformat(bounds))
    logger.debug('problem=' + pprint.pformat(problem))
    return solve_z3(bounds + problem, x_z3)


def nn_norm_l1(dim: int):
  """NN to compute L1 norm of a vector [x1, ..., xk], where k = dim.
  
  Args:
    dim: dimensionality of input vector.
  """
  net = nn.Sequential(
    nn.Linear(dim, 2*dim, bias=False),
    nn.ReLU(),
    nn.Linear(4, 1, bias=False),
  )

  with torch.no_grad():
    net[0].weight = nn.Parameter(
      torch.hstack([torch.eye(2, 2), torch.eye(2, 2) * -1]).T )
    net[2].weight = nn.Parameter(torch.ones(1, 4))

  return net


class ABVComposite(nn.Module):
  """Composite network containing A, B, and V. This network takes
  (x, y) as input, where x is a sample from the state space and y is 
  an error variable, and returns the following as output: 
  ( ||y||_1 - B(x), V(x) - V(A(x) + y) )  (Eq. 1)
  
  Assumption. Both x and y are passed as 2D-Tensors with only one 
  row and matching number of columns. If this assumption is true, 
  output is also a 2D-Tensor with only one row and two columns.
  """
  def __init__(self, A, B, V, dim):
    super().__init__()
    self.A = A
    self.B = B
    self.V = V
    self.NormL1 = nn_norm_l1(dim)

  def forward(self, x, y):
    v = self.V(x)
    vp = self.V(self.A(x) + y)
    norm_y = self.NormL1(y)
    b = self.B(x)
    return torch.cat([norm_y + -1*b, v + -1*vp], dim=1)


class Verifier_Reach_ABV(Verifier):
  def __init__(self, models, env, F):
    self.A, self.B, self.V = models
    self.env = env
    self.F = F

  def chk(self):
    cexs = [self.chk_abst(), self.chk_dec()]
    return [cex for cex in cexs if len(cex) != 0]

  def chk_abst(self):
    """Check the Abstraction-Bound condition using DReal.

    As this check involves a possibly nonlinear function F (hence,
    an NRA query), this method always uses DReal, and need not be
    implemented in subclasses of Verifier_Reach_ABV.
    """
    logger.info('Checking the Abstraction-Bound condition ...')
    x_sp = X(self.env.dim)
    x_dr = [dreal.Variable(f'x_{i}') for i in range(self.env.dim)]
    var = {x_sp[i]: x_dr[i] for i in range(self.env.dim)}

    # err = || A(x) - f(x) ||_1
    err = Net(self.A, x_sp) - self.F(x_sp)
    err = Norm_L1(err)
    # b = B(x). We need to reshape b to be a scalar, rather than a
    # matrix with only one element.
    b = Net(self.B, x_sp)
    assert b.shape == (1, 1)
    b = b[0]

    bounds = sympy_to_dreal(BoundIn(self.env.bnd, x_sp), var)
    problem = sympy_to_dreal(err > b, var)
    return solve_dreal(dreal.And(bounds, problem), x_dr)

  @abstractmethod
  def chk_dec(self):
    ...


class Verifier_Reach_ABV_Marabou(Verifier_Reach_ABV):
  def chk_dec(self):
    abv = ABVComposite(
      self.A, self.B, self.V, self.env.dim)
    x, y = torch.randn(1, 2), torch.randn(1, 2)
    o = abv(x, y)

    filename = 'marabou_drafts/abv.onnx'
    torch.onnx.export(
      abv, (x, y), filename,
      input_names=['x', 'y'],
      output_names=['o'])

    network = Marabou.read_onnx(filename)
    # Path(filename).unlink()

    x, y = network.inputVars[0][0], network.inputVars[1][0]
    o = network.outputVars[0][0]
    logger.debug(f'x = {x}')
    logger.debug(f'y = {y}')
    logger.debug(f'o = {o}')

    bnd = self.env.bnd
    dim = self.env.dim
    low = bnd.low.numpy()
    high = bnd.high.numpy()

    # Bounding y as well to avoid having infinite bounds.
    for i in range(dim):
      network.setLowerBound(x[i], low[i])
      network.setUpperBound(x[i], high[i])
      network.setLowerBound(y[i], low[i])
      network.setUpperBound(y[i], high[i])

    tgt = self.env.tgt
    low = tgt.low.numpy()
    high = tgt.high.numpy()
    for i in range(dim):
      # eq1. 1 * x[i] >= high[i]
      eq1 = MarabouCore.Equation(MarabouCore.Equation.GE)
      eq1.addAddend(1, x[i])
      eq1.setScalar(high[i])
      # eq2. 1 * x[i] <= low[i]
      eq2 = MarabouCore.Equation(MarabouCore.Equation.LE)
      eq2.addAddend(1, x[i])
      eq2.setScalar(low[i])
      network.addDisjunctionConstraint([[eq1], [eq2]])

    network.setUpperBound(o[0], 0.0)
    network.setUpperBound(o[1], 0.0)
    network.setLowerBound(o[0], -1e3)
    network.setLowerBound(o[1], -1e3)

    network.saveQuery('marabou_drafts/abv-query.txt')
    options = Marabou.createOptions(
      verbosity=0,
      tighteningStrategy='none',
    )
    chk, vals, _stats = network.solve(options=options)
    if chk == 'sat':
      return [vals[x[i]] for i in range(dim)]
    return None


class Verifier_Reach_ABV_Z3(Verifier_Reach_ABV):
  def chk_dec(self):
    logger.info('Checking the Decrease condition ...')
    dim = self.env.dim
    x_sp = X(dim)
    y_sp = Y(dim)
    x_z3 = z3.RealVector('x', dim)
    y_z3 = z3.RealVector('y', dim)
    var = {x_sp[i]: x_z3[i] for i in range(dim)}
    var.update({y_sp[i]: y_z3[i] for i in range(dim)})

    bounds, problem = [], []
    bounds.append(BoundIn(self.env.bnd, x_sp))
    bounds.append(BoundOut(self.env.tgt, x_sp))
    bounds = [sympy_to_z3(b, var) for b in bounds]

    # ||y||_1 <= B(x)
    norm_y = sympy_to_z3(Norm_L1(y_sp), var)
    b = sympy_to_z3(Net(self.B, x_sp)[0], var)
    problem.append(norm_y <= b)

    # V(x) <= V( A(x) + y) )
    v = sympy_to_z3(Net(self.V, x_sp)[0], var)
    vp = sympy_to_z3(
      Net(self.V, Net(self.A, x_sp) + y_sp)[0], var)
    problem.append(v <= vp)
    # logger.debug('bounds=' + pprint.pformat(bounds))
    # logger.debug('problem=' + pprint.pformat(problem))
    return solve_z3(bounds + problem, x_z3)
